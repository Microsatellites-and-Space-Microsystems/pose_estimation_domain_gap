{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFRecords_from_csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR49SNx8Q4D1"
      },
      "source": [
        "# Create TFRecords files starting from csv data and images\n",
        "\n",
        "Note: this code is suitable for creating TFRecord files for both domain adversarial and domain agnostic training with no modifications. If the csv file contains also lightbox and sunlamp information, the images will be taken from the corresponding folder based on the class associated to the csv entry (synthetic = 1; lightbox = 2; sunlamp = 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCOB2A10KIn9"
      },
      "source": [
        "images_dir='speedplus\\\\speedplus'\n",
        "csv_dir='train.csv'\n",
        "output_path='TFRecords\\\\train{}.record' #Create this folder before running the script"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1G2vF54LHlG"
      },
      "source": [
        "#Import all required packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpLfVUSJujAb"
      },
      "source": [
        "#Define some utilities\n",
        "\n",
        "def int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def bytes_list_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "def float_feature(value):\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def float_list_feature(value):\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2a9K5H-K3IF"
      },
      "source": [
        "# Part of the code is adapted from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records\n",
        "\n",
        "def create_tf_example(row, path):\n",
        "\n",
        "    image_filename=row[0]\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(image_filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    \n",
        "    width = 1920\n",
        "    height = 1200\n",
        "\n",
        "    channels=image.mode\n",
        "\n",
        "    if channels==\"L\":\n",
        "      channels=1\n",
        "    elif channels==\"RGB\":\n",
        "      channels=3\n",
        "\n",
        "    image_filename=image_filename.encode('utf8')\n",
        "    image_format = ('jpg').encode('utf8')\n",
        "\n",
        "    q_1 = row[1]\n",
        "    q_2 = row[2]\n",
        "    q_3 = row[3]\n",
        "    q_4 = row[4]\n",
        "    Xc = row[5]\n",
        "    Yc = row[6]\n",
        "    Zc = row[7]\n",
        "    xmin = row[8]\n",
        "    ymin = row[9]\n",
        "    xmax = row[10]\n",
        "    ymax = row[11]\n",
        "    X_A=row[12]\n",
        "    Y_A=row[13]\n",
        "    X_B=row[14]\n",
        "    Y_B=row[15]\n",
        "    X_C=row[16]\n",
        "    Y_C=row[17]\n",
        "    X_D=row[18]\n",
        "    Y_D=row[19]\n",
        "    X_E=row[20]\n",
        "    Y_E=row[21]\n",
        "    X_F=row[22]\n",
        "    Y_F=row[23]\n",
        "    X_G=row[24]\n",
        "    Y_G=row[25]\n",
        "    X_H=row[26]\n",
        "    Y_H=row[27]\n",
        "    X_I=row[28]\n",
        "    Y_I=row[29]\n",
        "    X_L=row[30]\n",
        "    Y_L=row[31]\n",
        "    X_M=row[32]\n",
        "    Y_M=row[33]\n",
        "    dataset_class= row[34]\n",
        "    class_text = ('Tango').encode('utf8')\n",
        "\n",
        "    #Some fields are kept for compatibility with TF Object detection API\n",
        "    class_nr = 1\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/actual_channels': int64_feature(channels),\n",
        "        'image/channels': int64_feature(3),\n",
        "        'image/height': int64_feature(height),\n",
        "        'image/width': int64_feature(width),\n",
        "        'image/filename': bytes_feature(image_filename),\n",
        "        'image/dataset_class': int64_feature(dataset_class),\n",
        "        'image/encoded': bytes_feature(encoded_jpg),\n",
        "        'image/format': bytes_feature(image_format),\n",
        "        \n",
        "        'image/object/quaternions/q_1': float_feature(q_1),\n",
        "        'image/object/quaternions/q_2': float_feature(q_2),\n",
        "        'image/object/quaternions/q_3': float_feature(q_3),\n",
        "        'image/object/quaternions/q_4': float_feature(q_4),\n",
        "        \n",
        "        'image/object/position/Xc': float_feature(Xc),\n",
        "        'image/object/position/Yc': float_feature(Yc),\n",
        "        'image/object/position/Zc': float_feature(Zc),\n",
        "        \n",
        "        'image/object/bbox/xmin': float_feature(xmin),\n",
        "        'image/object/bbox/xmax': float_feature(xmax),\n",
        "        'image/object/bbox/ymin': float_feature(ymin),\n",
        "        'image/object/bbox/ymax': float_feature(ymax),\n",
        "        'image/object/class/text': bytes_feature(class_text),\n",
        "        'image/object/class/label': int64_feature(class_nr),  \n",
        "        \n",
        "        'image/object/kpts/X_A': float_feature(X_A),\n",
        "        'image/object/kpts/Y_A': float_feature(Y_A),\n",
        "        'image/object/kpts/X_B': float_feature(X_B),\n",
        "        'image/object/kpts/Y_B': float_feature(Y_B),\n",
        "        'image/object/kpts/X_C': float_feature(X_C),\n",
        "        'image/object/kpts/Y_C': float_feature(Y_C),\n",
        "        'image/object/kpts/X_D': float_feature(X_D),\n",
        "        'image/object/kpts/Y_D': float_feature(Y_D),\n",
        "        'image/object/kpts/X_E': float_feature(X_E),\n",
        "        'image/object/kpts/Y_E': float_feature(Y_E),\n",
        "        'image/object/kpts/X_F': float_feature(X_F),\n",
        "        'image/object/kpts/Y_F': float_feature(Y_F),                \n",
        "        'image/object/kpts/X_G': float_feature(X_G),\n",
        "        'image/object/kpts/Y_G': float_feature(Y_G),\n",
        "        'image/object/kpts/X_H': float_feature(X_H),\n",
        "        'image/object/kpts/Y_H': float_feature(Y_H),\n",
        "        'image/object/kpts/X_I': float_feature(X_I),\n",
        "        'image/object/kpts/Y_I': float_feature(Y_I),\n",
        "        'image/object/kpts/X_L': float_feature(X_L),\n",
        "        'image/object/kpts/Y_L': float_feature(Y_L),\n",
        "        'image/object/kpts/X_M': float_feature(X_M),\n",
        "        'image/object/kpts/Y_M': float_feature(Y_M), \n",
        "    }))\n",
        "    return tf_example"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyzQdRv9zDnx"
      },
      "source": [
        "Run the following cell to create the TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoviZ8YMLFS7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "1bcc7d21-9a1c-4b79-8b99-14a833903dca"
      },
      "source": [
        "#Define the desired number of TFRecords files\n",
        "number_of_tfrecords_files=100\n",
        "\n",
        "#Read csv file content\n",
        "csv = pd.read_csv(csv_dir).values\n",
        "\n",
        "number_of_images_per_file=np.floor(len(csv)/number_of_tfrecords_files).astype('int32')\n",
        "images_processed=0\n",
        "images_index_start=0\n",
        "images_index_end=number_of_images_per_file\n",
        "\n",
        "for i in range(number_of_tfrecords_files):\n",
        "    writer = tf.python_io.TFRecordWriter(output_path.format(i))\n",
        "    \n",
        "    \n",
        "    for row in csv[images_index_start:images_index_end]:\n",
        "      images_processed+=1\n",
        "      features=row\n",
        "\n",
        "      if row[34]==1:\n",
        "        subfolder='synthetic'\n",
        "        images_dir_full = os.path.join(images_dir,subfolder,'images')\n",
        "\n",
        "      elif row[34]==2:\n",
        "        subfolder='lightbox'\n",
        "        images_dir_full = os.path.join(images_dir,subfolder,'images')\n",
        "\n",
        "      elif row[34]==3:\n",
        "        subfolder='sunlamp'\n",
        "        images_dir_full = os.path.join(images_dir,subfolder,'images')\n",
        "\n",
        "      \n",
        "      tf_example = create_tf_example(row, images_dir_full)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    images_index_start=images_index_end\n",
        "    images_index_end=(i+2)*number_of_images_per_file\n",
        "\n",
        "    if i==number_of_tfrecords_files-2:\n",
        "      images_index_end=len(csv)\n",
        "    writer.close()\n",
        "    print('Successfully created the TFRecord file: {}'.format(output_path.format(i)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: C:\\Users\\Alessandro Lotti\\Documents\\MATLAB\\Matlab_codes\\SPEC_2022_tools_v0\\submission1\\ai22\\TFRecords\\train0.record\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mC:\\Users\\ALESSA~1\\AppData\\Local\\Temp/ipykernel_40832/3715635561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m       \u001b[0mtf_example\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tf_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_dir_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m       \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mimages_index_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_index_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\tf_record.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    311\u001b[0m       \u001b[0mrecord\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[1;32m--> 313\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}