{"cells":[{"cell_type":"markdown","id":"411ef2ad","metadata":{"id":"411ef2ad","papermill":{"duration":0.025154,"end_time":"2022-05-26T16:05:38.966079","exception":false,"start_time":"2022-05-26T16:05:38.940925","status":"completed"},"tags":[]},"source":["# Perform inference"]},{"cell_type":"markdown","source":["This code allows to perform inference of CNN-ViT models. The Notebook can run on both hosted and local runtimes."],"metadata":{"id":"Hx1yk2lSIMOT"},"id":"Hx1yk2lSIMOT"},{"cell_type":"markdown","source":["# Preliminaries"],"metadata":{"id":"WDq8yVFyIXFU"},"id":"WDq8yVFyIXFU"},{"cell_type":"markdown","source":["Install required packages."],"metadata":{"id":"uXc2ci_oImlx"},"id":"uXc2ci_oImlx"},{"cell_type":"code","source":["!pip install git+https://github.com/Microsatellites-and-Space-Microsystems/pose_estimation_domain_gap --quiet"],"metadata":{"id":"aHt8RdoiIi-L"},"id":"aHt8RdoiIi-L","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Provide access to Google Drive."],"metadata":{"id":"llJOyCaUJeGL"},"id":"llJOyCaUJeGL"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"Sm9sGinrJfE6"},"id":"Sm9sGinrJfE6","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the paths to NN weights."],"metadata":{"id":"PifeHLrEJfuC"},"id":"PifeHLrEJfuC"},{"cell_type":"code","execution_count":null,"id":"aed14b55","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:06:38.116548Z","iopub.status.busy":"2022-05-26T16:06:38.116269Z","iopub.status.idle":"2022-05-26T16:06:38.120864Z","shell.execute_reply":"2022-05-26T16:06:38.119986Z"},"id":"aed14b55","papermill":{"duration":0.033359,"end_time":"2022-05-26T16:06:38.123227","exception":false,"start_time":"2022-05-26T16:06:38.089868","status":"completed"},"tags":[]},"outputs":[],"source":["weight_path = '/content/gdrive/MyDrive/.../my_first_CNN_ViT.h5'\n","\n","#Output file will be in json format\n","inference = 'sunlamp' #sunlamp / lightbox\n","images_folder = '/content/gdrive/MyDrive/SPEC21_test_images/'+inference\n","json_dest_file = '/content/gdrive/MyDrive/my_first_cnnvit_inference_'+inference+'.json'"]},{"cell_type":"markdown","source":["# Initialize model"],"metadata":{"id":"__Nse-NmJyeb"},"id":"__Nse-NmJyeb"},{"cell_type":"markdown","source":["Initialize the encoder (EfficientNet backbone + ViT)."],"metadata":{"id":"rGAyF1afKuSl"},"id":"rGAyF1afKuSl"},{"cell_type":"code","execution_count":null,"id":"8f3eee99","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:07:32.971601Z","iopub.status.busy":"2022-05-26T16:07:32.971181Z","iopub.status.idle":"2022-05-26T16:07:33.153569Z","shell.execute_reply":"2022-05-26T16:07:33.152461Z"},"papermill":{"duration":0.216096,"end_time":"2022-05-26T16:07:33.156389","exception":false,"start_time":"2022-05-26T16:07:32.940293","status":"completed"},"tags":[],"id":"8f3eee99"},"outputs":[],"source":["from models_and_layers.efficientnet_lite import EfficientNetLiteB4\n","from models_and_layers.vit_layers import AddPositionEmbs, TransformerBlock\n","import tensorflow as tf\n","\n","#Code adapted from https://github.com/faustomorales/vit-keras\n","#Licensed under Apache 2.0 license\n","#Removed classToken\n","\n","def build_encoder(\n","    input_shape=(320, 512, 3),\n","    patch_size=4,\n","    num_layers=6,\n","    hidden_size=256,\n","    num_heads=8,\n","    mlp_dim=2048,\n","    dropout=0.1\n","):\n","    \"\"\"Build transformer encoder.\n","\n","    Args:\n","        input_shape: The size of input images.\n","        patch_size: The size of each patch (must fit evenly in image_size)\n","        num_layers: The number of transformer layers to use.\n","        hidden_size: The number of filters to use\n","        num_heads: The number of transformer heads\n","        mlp_dim: The number of dimensions for the MLP output in the transformers.\n","        dropout_rate: fraction of the units to drop for dense layers.\n","    \"\"\"\n","    \n","    inputlayer=tf.keras.layers.Input(shape=(input_shape[0], input_shape[1], 3))\n","\n","    model = EfficientNetLiteB4(weights=None, input_shape=(input_shape[0], input_shape[1], 3),include_top=False)(inputlayer)\n","    #model=tf.keras.models.Model(inputs=model.input,outputs=model.layers[-1].output)(inputlayer)\n","    #x = tf.keras.layers.Conv2D(64,1)(model)\n","    #x = tf.keras.layers.Input(shape=(image_size[0], image_size[1], 3))\n","    y = tf.keras.layers.Conv2D(\n","        filters=hidden_size,\n","        kernel_size=patch_size,\n","        strides=patch_size,\n","        padding=\"valid\",\n","        name=\"embedding\",\n","        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1116),\n","    )(model)\n","    y = tf.keras.layers.Reshape((y.shape[1] * y.shape[2], hidden_size))(y)\n","\n","    y = AddPositionEmbs(name=\"Transformer/posembed_input\")(y)\n","    for n in range(num_layers):\n","        y, _ = TransformerBlock(\n","            num_heads=num_heads,\n","            mlp_dim=mlp_dim,\n","            dropout=dropout,\n","            name=f\"Transformer/encoderblock_{n}\",\n","        )(y)\n","    y = tf.keras.layers.LayerNormalization(\n","        epsilon=1e-6, name=\"Transformer/encoder_norm\"\n","    )(y)\n","\n","    y=tf.keras.layers.GlobalAveragePooling1D()(y)\n","    #y=tf.keras.layers.Flatten()(y)\n","    \n","    return tf.keras.models.Model(inputs=inputlayer, outputs=y)"]},{"cell_type":"markdown","source":["Initialize regression head."],"metadata":{"id":"wFe74u22KzcC"},"id":"wFe74u22KzcC"},{"cell_type":"code","execution_count":null,"id":"d7326f96","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:07:33.217556Z","iopub.status.busy":"2022-05-26T16:07:33.217235Z","iopub.status.idle":"2022-05-26T16:07:33.226689Z","shell.execute_reply":"2022-05-26T16:07:33.225941Z"},"papermill":{"duration":0.041288,"end_time":"2022-05-26T16:07:33.228696","exception":false,"start_time":"2022-05-26T16:07:33.187408","status":"completed"},"tags":[],"id":"d7326f96"},"outputs":[],"source":["class kpts_regressor(tf.keras.Model):\n","  def __init__(self,hidden_dim,num_keypoints):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.num_keypoints = num_keypoints\n","        self.basic_layers = tf.keras.Sequential(\n","            [tf.keras.layers.Dropout(0.1,seed=43),\n","             tf.keras.layers.Dense(self.hidden_dim,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=9001)),\n","          tf.keras.layers.Dropout(0.1,seed=819),\n","          tf.keras.layers.Dense(self.hidden_dim/2,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=901)),\n","          tf.keras.layers.Dense(22,kernel_initializer=tf.keras.initializers.GlorotUniform(seed=976),name='kpts'),\n","         ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"]},{"cell_type":"markdown","source":["Build the model and restore weights."],"metadata":{"id":"ef0s8_5yK2-y"},"id":"ef0s8_5yK2-y"},{"cell_type":"code","execution_count":null,"id":"f3024af9","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:07:33.287337Z","iopub.status.busy":"2022-05-26T16:07:33.286395Z","iopub.status.idle":"2022-05-26T16:07:41.823968Z","shell.execute_reply":"2022-05-26T16:07:41.823246Z"},"papermill":{"duration":8.569376,"end_time":"2022-05-26T16:07:41.826420","exception":false,"start_time":"2022-05-26T16:07:33.257044","status":"completed"},"tags":[],"id":"f3024af9"},"outputs":[],"source":["#Vit tiny:\n","hidden_dim=192\n","num_keypoints = 11\n","input_shape=[320, 512, 3]\n","inputlayer=tf.keras.layers.Input(shape=(input_shape[0], input_shape[1], 3))\n","\n","encoder=test=build_encoder(input_shape=(320, 512, 3),\n","    patch_size=1,\n","    num_layers=1,\n","    hidden_size=hidden_dim,\n","    num_heads=3,\n","    mlp_dim=hidden_dim*3,\n","    dropout=0.1\n","  )(inputlayer)\n","encoder=tf.keras.models.Model([inputlayer], [encoder])\n","regressor_kpts = kpts_regressor(hidden_dim,num_keypoints)(encoder.output)\n","network=tf.keras.models.Model([encoder.input], [regressor_kpts])\n","\n","# Restore the weights\n","\n","network.load_weights(weight_path)"]},{"cell_type":"markdown","id":"924f1b64","metadata":{"id":"924f1b64","papermill":{"duration":0.040263,"end_time":"2022-05-26T16:07:43.096980","exception":false,"start_time":"2022-05-26T16:07:43.056717","status":"completed"},"tags":[]},"source":["# Tango model and camera matrix"]},{"cell_type":"code","execution_count":null,"id":"21b63fa1","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:07:43.179527Z","iopub.status.busy":"2022-05-26T16:07:43.179239Z","iopub.status.idle":"2022-05-26T16:07:43.194733Z","shell.execute_reply":"2022-05-26T16:07:43.193641Z"},"id":"21b63fa1","papermill":{"duration":0.05946,"end_time":"2022-05-26T16:07:43.197218","exception":false,"start_time":"2022-05-26T16:07:43.137758","status":"completed"},"tags":[]},"outputs":[],"source":["#SPEED 3D Model\n","\n","import numpy as np\n","\n","# Camera matrix updated to SPEED+\n","cameraMatrix=np.array([[2988.579516381556, 0, 960],[0,2988.340115917612, 600],[0,0,1]])\n","\n","#(k1,k2,p1,p2[,k3])\n","distCoeffs = np.array([-0.223830166065107, 0.514097970891064, -6.649961199834066e-04, -2.140477166748459e-04, -0.131242274290774])\n","#Points coordinates on Tango's frame:\n","\n","#Create a np array \"objectPoints\" with size num_keypoints x 3 (x, y, z coordinates) containing the satellite 3D model (keypoints coordinates)\n","\n","#objectPoints=...\n","objectPoints=objectPoints.reshape(11,3)\n"]},{"cell_type":"markdown","id":"df455252","metadata":{"id":"df455252","papermill":{"duration":0.039955,"end_time":"2022-05-26T16:07:43.277881","exception":false,"start_time":"2022-05-26T16:07:43.237926","status":"completed"},"tags":[]},"source":["# Load images"]},{"cell_type":"code","execution_count":null,"id":"66565dbb","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:07:43.362039Z","iopub.status.busy":"2022-05-26T16:07:43.361754Z","iopub.status.idle":"2022-05-26T16:08:03.554919Z","shell.execute_reply":"2022-05-26T16:08:03.553937Z"},"id":"66565dbb","papermill":{"duration":20.238391,"end_time":"2022-05-26T16:08:03.557258","exception":false,"start_time":"2022-05-26T16:07:43.318867","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","\n","img=[]\n","for path in os.listdir(images_folder):\n","    full_path = os.path.join(images_folder, path)\n","    if os.path.isfile(full_path) and os.path.splitext(full_path)[1]=='.jpg':\n","        img.append(full_path)\n","\n","print(len(img))"]},{"cell_type":"markdown","id":"3aee9026","metadata":{"id":"3aee9026","papermill":{"duration":0.039948,"end_time":"2022-05-26T16:08:03.728509","exception":false,"start_time":"2022-05-26T16:08:03.688561","status":"completed"},"tags":[]},"source":["# Run inference"]},{"cell_type":"code","execution_count":null,"id":"2dd1c363","metadata":{"execution":{"iopub.execute_input":"2022-05-26T16:08:04.172537Z","iopub.status.busy":"2022-05-26T16:08:04.171917Z","iopub.status.idle":"2022-05-26T17:01:06.515916Z","shell.execute_reply":"2022-05-26T17:01:06.513459Z"},"id":"2dd1c363","papermill":{"duration":3182.389586,"end_time":"2022-05-26T17:01:06.519324","exception":false,"start_time":"2022-05-26T16:08:04.129738","status":"completed"},"tags":[]},"outputs":[],"source":["import time\n","from PIL import Image\n","import cv2\n","from scipy.spatial.transform import Rotation as Rot\n","\n","image_width = 1920\n","image_height = 1200\n","\n","np.set_printoptions(threshold=60000)\n","\n","num_keypoints = 11\n","\n","#Initialize variables to export data\n","images_names=[]\n","\n","image_overall_time=np.zeros((len(img),1))\n","export_keypoints=np.zeros((len(img),num_keypoints*2))\n","network_inference_time=np.zeros((len(img),1))\n","\n","load_image_time=np.zeros((len(img),1))\n","\n","export_PnP_success=np.zeros((len(img),1))\n","export_position=np.zeros((len(img),3))\n","export_quat=np.zeros((len(img),4))\n","\n","export_inliers_nr=np.zeros((len(img),1))\n","\n","export_position_LM=np.zeros((len(img),3))\n","export_quat_LM=np.zeros((len(img),4))\n","PnP_time=np.zeros((len(img),1))\n","LM_time=np.zeros((len(img),1))\n","\n","inliers_indices=np.zeros((1,11))\n","\n","i=-1\n","for image_path in img:\n","    i+=1\n","    print(i)\n","    \n","    images_names.append(os.path.basename(image_path))\n","    image_time_start = time.time()\n","    \n","    image_pil=Image.open(image_path)\n","    image=np.asarray(image_pil) \n","    image=np.expand_dims(image,-1)\n","\n","    load_image_time[i,:]=time.time()-image_time_start\n","\n","    image=tf.image.resize(image,\n","                          [320,512],\n","                          method=tf.image.ResizeMethod.BILINEAR,\n","                          antialias=False\n","    )\n","    \n","    image=(image - 127.00) / 128.00\n","\n","    image = tf.image.grayscale_to_rgb(image)\n","    image=np.expand_dims(image,0)\n","\n","    start = time.time()\n","    output=network(image)\n","    network_inference_time[i,:]=time.time()-start\n","\n","    keypoints=output.numpy()\n","\n","    keypoints=np.reshape(keypoints,[num_keypoints*2,1])\n","\n","    keypoints=keypoints.reshape(num_keypoints,2)\n","\n","    keypoints[:,0]=keypoints[:,0]*1920\n","    keypoints[:,1]=keypoints[:,1]*1200\n","\n","    export_keypoints[i,:]=keypoints.reshape(1,num_keypoints*2)\n","\n","    start=time.time()\n","    success, R_vec, t_vec, inliers = cv2.solvePnPRansac(objectPoints,keypoints,cameraMatrix,distCoeffs,flags=cv2.SOLVEPNP_EPNP,reprojectionError=5)\n","    PnP_time[i,:]=time.time()-start\n","\n","    Rotation_matrix, _ = cv2.Rodrigues(R_vec)\n","    scipy_rotation_matrix=Rot.from_matrix(Rotation_matrix)\n","    quat=scipy_rotation_matrix.as_quat()\n","\n","    if success==True:\n","        export_PnP_success[i,:]=success\n","        export_inliers_nr[i,:]=len(inliers)\n","    \n","    export_position[i,:]=t_vec.transpose()\n","    export_quat[i,:]=quat\n","\n","    start=time.time()\n","    R_vec, t_vec=cv2.solvePnPRefineLM(objectPoints[inliers,:],keypoints[inliers,:],cameraMatrix,distCoeffs,R_vec, t_vec)\n","    LM_time[i,:]=time.time()-start\n","\n","    Rotation_matrix_LM, _ = cv2.Rodrigues(R_vec)\n","    scipy_rotation_matrix_LM=Rot.from_matrix(Rotation_matrix_LM)\n","    quat_LM=scipy_rotation_matrix_LM.as_quat()\n","    export_position_LM[i,:]=t_vec.transpose()\n","    export_quat_LM[i,:]=quat_LM\n","\n","    image_overall_time[i,:]=time.time()-image_time_start"]},{"cell_type":"code","execution_count":null,"id":"360d7660","metadata":{"execution":{"iopub.execute_input":"2022-05-26T17:01:21.797694Z","iopub.status.busy":"2022-05-26T17:01:21.797379Z","iopub.status.idle":"2022-05-26T17:01:22.763551Z","shell.execute_reply":"2022-05-26T17:01:22.762370Z"},"id":"360d7660","papermill":{"duration":3.523528,"end_time":"2022-05-26T17:01:22.766781","exception":false,"start_time":"2022-05-26T17:01:19.243253","status":"completed"},"tags":[]},"outputs":[],"source":["import json\n","\n","i=-1;\n","for item in images_names:\n","  i=i+1;\n","  if i==0:\n","    data_all=[{\n","      'image': images_names[i],\n","      'network_inference_time': (network_inference_time[i]).tolist(),\n","      'keypoints': (export_keypoints[i]).tolist(),\n","      'PnP_success': (export_PnP_success[i]).tolist(),\n","      'PnP_inliers_nr': (export_inliers_nr[i]).tolist(),\n","      'PnP_time': (PnP_time[i]).tolist(),\n","      'LM_time': (LM_time[i]).tolist(),\n","      'Load_time': (load_image_time[i]).tolist(),\n","      'position': (export_position[i]).tolist(),\n","      'quaternions': (export_quat[i]).tolist(),\n","      'position_LM': (export_position_LM[i]).tolist(),\n","      'quaternions_LM': (export_quat_LM[i]).tolist(),\n","      'overall_image_time': (image_overall_time[i]).tolist(),\n","    }]\n","  else:\n","    data_item={\n","      'image': images_names[i],\n","      'network_inference_time': (network_inference_time[i]).tolist(),\n","      'keypoints': (export_keypoints[i]).tolist(),\n","      'PnP_success': (export_PnP_success[i]).tolist(),\n","      'PnP_inliers_nr': (export_inliers_nr[i]).tolist(),\n","      'PnP_time': (PnP_time[i]).tolist(),\n","      'LM_time': (LM_time[i]).tolist(),\n","      'Load_time': (load_image_time[i]).tolist(),\n","      'position': (export_position[i]).tolist(),\n","      'quaternions': (export_quat[i]).tolist(),\n","      'position_LM': (export_position_LM[i]).tolist(),\n","      'quaternions_LM': (export_quat_LM[i]).tolist(),\n","      'overall_image_time': (image_overall_time[i]).tolist(),\n","    }\n","    data_all.append(data_item)  \n","\n","parsed = json.dumps(data_all,indent=4)\n","\n","with open(os.path.join(json_dest_file),'w') as f:\n","        f.write(parsed)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":3361.035252,"end_time":"2022-05-26T17:01:28.721046","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-05-26T16:05:27.685794","version":"2.3.4"},"colab":{"name":"CNN_ViT_inference.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}