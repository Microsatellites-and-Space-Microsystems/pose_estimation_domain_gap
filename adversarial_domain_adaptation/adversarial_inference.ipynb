{"cells":[{"cell_type":"markdown","id":"e6a79b9e","metadata":{"id":"e6a79b9e","papermill":{"duration":0.014673,"end_time":"2022-05-28T10:49:08.853680","exception":false,"start_time":"2022-05-28T10:49:08.839007","status":"completed"},"tags":[]},"source":["# Perform inference"]},{"cell_type":"markdown","source":["This code allows to perform inference upon SDN and LRN training. The Notebook can run on both hosted and local runtimes."],"metadata":{"id":"g8KjSVhpFxHA"},"id":"g8KjSVhpFxHA"},{"cell_type":"markdown","source":["# Preliminaries"],"metadata":{"id":"cDHilCpnF_D_"},"id":"cDHilCpnF_D_"},{"cell_type":"markdown","source":["Install required packages."],"metadata":{"id":"yq8zFvRUInQ8"},"id":"yq8zFvRUInQ8"},{"cell_type":"code","source":["!pip install git+https://github.com/Microsatellites-and-Space-Microsystems/pose_estimation_domain_gap --quiet"],"metadata":{"id":"zIDo48RPIjvt"},"id":"zIDo48RPIjvt","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Provide access to Google Drive."],"metadata":{"id":"hBAzVO1pHFku"},"id":"hBAzVO1pHFku"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"rFOs8OjlGGNa"},"id":"rFOs8OjlGGNa","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the paths to NNs weights."],"metadata":{"id":"EhiOZwP0HH8-"},"id":"EhiOZwP0HH8-"},{"cell_type":"code","execution_count":null,"id":"3d574487","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:49:30.019578Z","iopub.status.busy":"2022-05-28T10:49:30.017704Z","iopub.status.idle":"2022-05-28T10:49:30.025688Z","shell.execute_reply":"2022-05-28T10:49:30.024731Z"},"id":"3d574487","papermill":{"duration":0.019093,"end_time":"2022-05-28T10:49:30.027957","exception":false,"start_time":"2022-05-28T10:49:30.008864","status":"completed"},"tags":[]},"outputs":[],"source":["sdn_weight_path = '/content/gdrive/MyDrive/.../my_first_SDN.h5'\n","lrn_weight_path = '/content/gdrive/MyDrive/.../my_first_LRN.h5'\n","\n","#Output file will be in json format\n","inference = 'sunlamp' #sunlamp / lightbox\n","images_folder = '/content/gdrive/MyDrive/SPEC21_test_images/'+inference\n","json_dest_file = '/content/gdrive/MyDrive/my_first_inference_'+inference+'.json'"]},{"cell_type":"markdown","id":"44667a29","metadata":{"id":"44667a29","papermill":{"duration":0.00696,"end_time":"2022-05-28T10:49:30.042498","exception":false,"start_time":"2022-05-28T10:49:30.035538","status":"completed"},"tags":[]},"source":["# Initialize SDN"]},{"cell_type":"markdown","source":["Use these cells to initialize a Swin based SDN."],"metadata":{"id":"CJLDtXsEIVVV"},"id":"CJLDtXsEIVVV"},{"cell_type":"code","execution_count":null,"id":"4aa288c5","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:49:30.058717Z","iopub.status.busy":"2022-05-28T10:49:30.058314Z","iopub.status.idle":"2022-05-28T10:49:36.362055Z","shell.execute_reply":"2022-05-28T10:49:36.360965Z"},"id":"4aa288c5","papermill":{"duration":6.314967,"end_time":"2022-05-28T10:49:36.364656","exception":false,"start_time":"2022-05-28T10:49:30.049689","status":"completed"},"tags":[]},"outputs":[],"source":["from models_and_layers.tfswin import SwinTransformerTiny224 as transformerEncoder\n","import tensorflow as tf\n","\n","def get_encoder(input_shape):\n","\n","    input = tf.keras.layers.Input(shape=(input_shape, input_shape, 3))\n","    model=transformerEncoder(include_top=False)(input)\n","    x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(model)\n","    model = tf.keras.models.Model(inputs=input, outputs=x)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"id":"c53a7cba","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:49:36.381374Z","iopub.status.busy":"2022-05-28T10:49:36.380665Z","iopub.status.idle":"2022-05-28T10:49:36.806299Z","shell.execute_reply":"2022-05-28T10:49:36.805262Z"},"id":"c53a7cba","papermill":{"duration":0.436688,"end_time":"2022-05-28T10:49:36.808778","exception":false,"start_time":"2022-05-28T10:49:36.372090","status":"completed"},"tags":[]},"outputs":[],"source":["class Discriminator(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","          [tf.keras.layers.Dense(self.hidden_dim*4,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=422)),\n","          tf.keras.layers.Dense(self.hidden_dim,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=342)),\n","          tf.keras.layers.Dense(1,name='cls',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=324)),\n","          ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x\n","  \n","class Regressor(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","        [tf.keras.layers.Dense(hidden_dim*4,activation='gelu',name='bbox1',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3256)),\n","         tf.keras.layers.Dense(hidden_dim,activation='gelu',name='bbox2',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=768)),\n","         tf.keras.layers.Dense(4,activation='linear',name='bbox',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=4236)),\n","         ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"]},{"cell_type":"code","source":["# Build the model and restore weights.\n","\n","input_shape = 224\n","hidden_dim=768\n","\n","new_encoder=get_encoder(input_shape)\n","discriminator = Discriminator(hidden_dim)(new_encoder.output)\n","regressor=Regressor(hidden_dim)(new_encoder.output)\n","sdn_network=tf.keras.models.Model([new_encoder.input], [discriminator,regressor])\n","\n","sdn_network.load_weights(sdn_weight_path)"],"metadata":{"id":"I36GoDtcH6lk"},"id":"I36GoDtcH6lk","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use these cells to initialize an EfficientNet based SDN."],"metadata":{"id":"aTOnHzaeJEcU"},"id":"aTOnHzaeJEcU"},{"cell_type":"code","source":["from models_and_layers.efficientnet import EfficientNetV1B5\n","import tensorflow as tf\n","\n","class get_encoder(tf.keras.Model):\n","  def __init__(self,hidden_dim,input_shape):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential([\n","    EfficientNetV1B5(num_classes=0,input_shape=(input_shape,input_shape,3),pretrained=\"imagenet\"),\n","    tf.keras.layers.Conv2D(self.hidden_dim,1,kernel_initializer=tf.keras.initializers.GlorotUniform(seed=927)),\n","    tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')])\n","         \n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"],"metadata":{"id":"usyuju0JJGtk"},"id":"usyuju0JJGtk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Discriminator(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","          [tf.keras.layers.Dense(self.hidden_dim*4,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=422)),\n","          tf.keras.layers.Dense(self.hidden_dim,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=342)),\n","          tf.keras.layers.Dense(1,name='cls',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=324)),\n","          ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x\n","  \n","class Regressor(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","        [tf.keras.layers.Dense(hidden_dim*4,activation='gelu',name='bbox1',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3256)),\n","         tf.keras.layers.Dense(hidden_dim,activation='gelu',name='bbox2',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=768)),\n","         tf.keras.layers.Dense(4,activation='linear',name='bbox',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=4236)),\n","         ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"],"metadata":{"id":"c8uB12JEJJx8"},"id":"c8uB12JEJJx8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the model and restore weights.\n","\n","input_shape = 224  #Assumed squared\n","hidden_dim=768     #Output size of the encoder\n","input=tf.keras.layers.Input(shape=(input_shape, input_shape, 3))\n","\n","encoder=get_encoder(hidden_dim,input_shape)\n","discriminator = Discriminator(hidden_dim)(encoder(input))\n","regressor=Regressor(hidden_dim)(encoder(input))\n","sdn_network=tf.keras.models.Model([encoder.input], [discriminator,regressor])\n","\n","sdn_network.load_weights(sdn_weight_path)"],"metadata":{"id":"E6hLQFiiJLlE"},"id":"E6hLQFiiJLlE","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"7c761eb0","metadata":{"id":"7c761eb0","papermill":{"duration":0.007015,"end_time":"2022-05-28T10:49:36.823531","exception":false,"start_time":"2022-05-28T10:49:36.816516","status":"completed"},"tags":[]},"source":["# Initialize LRN"]},{"cell_type":"markdown","source":["Use these cells to initialize a Swin based LRN."],"metadata":{"id":"guRAUKHvJki8"},"id":"guRAUKHvJki8"},{"cell_type":"code","source":["from models_and_layers.tfswin import SwinTransformerTiny224 as transformerEncoder\n","\n","def get_encoder(input_shape):\n","    \n","    input = tf.keras.layers.Input(shape=(input_shape, input_shape, 3))\n","    model=transformerEncoder(include_top=False)(input)\n","    x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(model)\n","    model = tf.keras.models.Model(inputs=input, outputs=x)\n","    \n","    return model"],"metadata":{"id":"0pcLDuqQJlCl"},"id":"0pcLDuqQJlCl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Discriminator(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","          [tf.keras.layers.Dense(self.hidden_dim*4,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1509)),\n","          tf.keras.layers.Dense(self.hidden_dim,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=9)),\n","          tf.keras.layers.Dense(1,name='cls',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3412)),\n","          ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x\n","  \n","class Regressor(tf.keras.Model):\n","  def __init__(self,hidden_dim,num_keypoints):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.num_keypoints = num_keypoints\n","        self.basic_layers = tf.keras.Sequential(\n","        [tf.keras.layers.Dense(hidden_dim*4,activation='gelu',name='kpts1',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=121)),\n","         tf.keras.layers.Dense(hidden_dim,activation='gelu',name='kpts2',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=432)),\n","         tf.keras.layers.Dense(num_keypoints*2,activation='linear',name='kpts',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3454)),\n","         ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"],"metadata":{"id":"rDgfwdQ8JnTH"},"id":"rDgfwdQ8JnTH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the model:\n","\n","input_shape = 224  #Assumed squared\n","hidden_dim=768    #Output size of the encoder\n","num_keypoints = 11 #Satellite's keypoints\n","\n","encoder=get_encoder(input_shape)\n","discriminator = Discriminator(hidden_dim)(encoder.output)\n","regressor=Regressor(hidden_dim,num_keypoints)(encoder.output)\n","lrn_network=tf.keras.models.Model([encoder.input], [discriminator,regressor])\n","\n","lrn_network.load_weights(lrn_weight_path)"],"metadata":{"id":"d-pHMWgoJo9c"},"id":"d-pHMWgoJo9c","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use these cells to initialize an EfficientNet based LRN."],"metadata":{"id":"k9t0LUgcJ3vD"},"id":"k9t0LUgcJ3vD"},{"cell_type":"code","source":["from models_and_layers.efficientnet import EfficientNetV1B5\n","\n","class get_encoder(tf.keras.Model):\n","  def __init__(self,hidden_dim,input_shape):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.num_keypoints = num_keypoints\n","        self.basic_layers = tf.keras.Sequential([\n","    EfficientNetV1B5(num_classes=0,input_shape=(input_shape,input_shape,3),pretrained=\"imagenet\"),\n","    tf.keras.layers.Conv2D(self.hidden_dim,1,kernel_initializer=tf.keras.initializers.GlorotUniform(seed=231)),\n","    tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')])\n","         \n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"],"metadata":{"id":"nVgp51ODKO2c"},"id":"nVgp51ODKO2c","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Discriminator(tf.keras.Model):\n","  def __init__(self,hidden_dim):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.basic_layers = tf.keras.Sequential(\n","          [tf.keras.layers.Dense(self.hidden_dim*4,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1509)),\n","          tf.keras.layers.Dense(self.hidden_dim,activation='gelu',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=9)),\n","          tf.keras.layers.Dense(1,name='cls',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3412)),\n","          ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x\n","  \n","class Regressor(tf.keras.Model):\n","  def __init__(self,hidden_dim,num_keypoints):\n","        super().__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.num_keypoints = num_keypoints\n","        self.basic_layers = tf.keras.Sequential(\n","        [tf.keras.layers.Dense(hidden_dim*4,activation='gelu',name='kpts1',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=121)),\n","         tf.keras.layers.Dense(hidden_dim,activation='gelu',name='kpts2',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=432)),\n","         tf.keras.layers.Dense(num_keypoints*2,activation='linear',name='kpts',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3454)),\n","         ]\n","        )\n","  def call(self, x):\n","    x = self.basic_layers(x)\n","    return x"],"metadata":{"id":"wbgRvWr-KTCD"},"id":"wbgRvWr-KTCD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the model:\n","\n","input_shape = 224  #Assumed squared\n","hidden_dim=768     #Output size of the encoder\n","num_keypoints = 11 #Satellite's keypoints\n","input=tf.keras.layers.Input(shape=(input_shape, input_shape, 3))\n","\n","encoder=get_encoder(hidden_dim,input_shape)\n","discriminator = Discriminator(hidden_dim)(encoder(input))\n","regressor=Regressor(hidden_dim,num_keypoints)(encoder(input))\n","lrn_network=tf.keras.models.Model([encoder.input], [discriminator,regressor])\n","\n","lrn_network.load_weights(lrn_weight_path)"],"metadata":{"id":"CsQXoiNYKTnL"},"id":"CsQXoiNYKTnL","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"c7b3a4dc","metadata":{"id":"c7b3a4dc","papermill":{"duration":0.011337,"end_time":"2022-05-28T10:50:08.700151","exception":false,"start_time":"2022-05-28T10:50:08.688814","status":"completed"},"tags":[]},"source":["# Tango model and camera matrix"]},{"cell_type":"code","execution_count":null,"id":"36077af7","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:50:08.725883Z","iopub.status.busy":"2022-05-28T10:50:08.724805Z","iopub.status.idle":"2022-05-28T10:50:08.742237Z","shell.execute_reply":"2022-05-28T10:50:08.741169Z"},"id":"36077af7","papermill":{"duration":0.032882,"end_time":"2022-05-28T10:50:08.744734","exception":false,"start_time":"2022-05-28T10:50:08.711852","status":"completed"},"tags":[]},"outputs":[],"source":["#SPEED 3D Model\n","\n","import numpy as np\n","\n","# Camera matrix updated to SPEED+\n","cameraMatrix=np.array([[2988.579516381556, 0, 960],[0,2988.340115917612, 600],[0,0,1]])\n","\n","#(k1,k2,p1,p2[,k3])\n","distCoeffs = np.array([-0.223830166065107, 0.514097970891064, -6.649961199834066e-04, -2.140477166748459e-04, -0.131242274290774])\n","#Points coordinates on Tango's frame:\n","\n","#Create a np array \"objectPoints\" with size num_keypoints x 3 (x, y, z coordinates) containing the satellite 3D model (keypoints coordinates)\n","\n","#objectPoints=...\n","objectPoints=objectPoints.reshape(11,3)\n"]},{"cell_type":"markdown","id":"40e87fa6","metadata":{"id":"40e87fa6","papermill":{"duration":0.011481,"end_time":"2022-05-28T10:50:08.768162","exception":false,"start_time":"2022-05-28T10:50:08.756681","status":"completed"},"tags":[]},"source":["# Load images"]},{"cell_type":"code","execution_count":null,"id":"3626780f","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:50:08.793186Z","iopub.status.busy":"2022-05-28T10:50:08.792788Z","iopub.status.idle":"2022-05-28T10:50:12.355972Z","shell.execute_reply":"2022-05-28T10:50:12.353659Z"},"id":"3626780f","papermill":{"duration":3.57853,"end_time":"2022-05-28T10:50:12.358399","exception":false,"start_time":"2022-05-28T10:50:08.779869","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","\n","img=[]\n","for path in os.listdir(images_folder):\n","    full_path = os.path.join(images_folder, path)\n","    if os.path.isfile(full_path) and os.path.splitext(full_path)[1]=='.jpg':\n","        img.append(full_path)\n","\n","print(len(img))"]},{"cell_type":"markdown","id":"1af933db","metadata":{"id":"1af933db","papermill":{"duration":0.012002,"end_time":"2022-05-28T10:50:12.382291","exception":false,"start_time":"2022-05-28T10:50:12.370289","status":"completed"},"tags":[]},"source":["# Run inference"]},{"cell_type":"code","execution_count":null,"id":"3581ac15","metadata":{"execution":{"iopub.execute_input":"2022-05-28T10:50:12.440365Z","iopub.status.busy":"2022-05-28T10:50:12.439597Z","iopub.status.idle":"2022-05-28T11:24:00.639255Z","shell.execute_reply":"2022-05-28T11:24:00.638065Z"},"id":"3581ac15","papermill":{"duration":2028.215554,"end_time":"2022-05-28T11:24:00.641672","exception":false,"start_time":"2022-05-28T10:50:12.426118","status":"completed"},"tags":[]},"outputs":[],"source":["import time\n","from PIL import Image\n","import cv2\n","from scipy.spatial.transform import Rotation as Rot\n","import numpy as np\n","#import matplotlib.pyplot as plt\n","\n","start_all=time.time()\n","image_width = 1920\n","image_height = 1200\n","\n","np.set_printoptions(threshold=60000)\n","\n","lrn_image_resolution = 224\n","sdn_image_resolution = 224\n","\n","#Initialize variables to export data\n","images_names=[]\n","image_overall_time=np.zeros((len(img),1))\n","export_keypoints=np.zeros((len(img),num_keypoints*2))\n","sdn_inference_time=np.zeros((len(img),1))\n","export_bbox_coords=np.zeros((len(img),4))\n","lrn_inference_time=np.zeros((len(img),1))\n","load_image_time=np.zeros((len(img),1))\n","\n","export_PnP_success=np.zeros((len(img),1))\n","export_position=np.zeros((len(img),3))\n","export_quat=np.zeros((len(img),4))\n","\n","export_inliers_nr=np.zeros((len(img),1))\n","\n","export_position_LM=np.zeros((len(img),3))\n","export_quat_LM=np.zeros((len(img),4))\n","PnP_time=np.zeros((len(img),1))\n","LM_time=np.zeros((len(img),1))\n","\n","#export_predicted_class_sdn=np.zeros((len(img),1))\n","#export_predicted_class_lrn=np.zeros((len(img),1))\n","i=-1\n","for image_path in img:\n","    i+=1\n","    print(i)\n","    \n","    images_names.append(os.path.basename(image_path))\n","    image_time_start = time.time()\n","\n","    image=Image.open(image_path)\n","    image=np.asarray(image) \n","    image=np.expand_dims(image,-1)\n","\n","    load_image_time[i,:]=time.time()-image_time_start\n","\n","    image_sdn=tf.image.resize(image,\n","                          [sdn_image_resolution,sdn_image_resolution],\n","                          method=tf.image.ResizeMethod.BILINEAR,\n","                          antialias=False\n","    )\n","    \n","    image_sdn = (image_sdn / 127.5) - 1.0\n","\n","    image_sdn = tf.image.grayscale_to_rgb(image_sdn)\n","    image_sdn=np.expand_dims(image_sdn,0)\n","\n","    start=time.time()\n","    output=sdn_network(image_sdn)\n","        \n","    bbox_coords=output[1]\n","\n","    #if output[0].numpy()<0:\n","    #  dataset_class = 0\n","    #else:\n","    #  dataset_class = 1\n","\n","    sdn_inference_time[i,:]=time.time()-start\n","\n","    [xmin,ymin,xmax,ymax]=np.reshape(bbox_coords.numpy(),[4])*[1920, 1200, 1920, 1200]\n","    export_bbox_coords[i,:]=[ymin,xmin,ymax,xmax]\n","    #export_predicted_class_sdn[i,:]=dataset_class\n","\n","    #Define the ROI\n","\n","    #Find the center coordinates and dimensions\n","    xc=(xmax+xmin)/2\n","    yc=(ymax+ymin)/2\n","\n","    bbox_w=max((xmax-xmin)*1.15,lrn_image_resolution)\n","    bbox_h=max((ymax-ymin)*1.15, lrn_image_resolution)\n","\n","    xmin=xc-bbox_w/2\n","    ymin=yc-bbox_h/2\n","    \n","    \n","    xmin=max(xmin,0)\n","    ymin=max(ymin,0)\n","\n","    xmin=np.floor(xmin)\n","    ymin=np.floor(ymin)\n","    bbox_h=np.floor(bbox_h)\n","    bbox_w=np.floor(bbox_w)\n","    \n","    cropped_img = image[int(ymin):int(min(1200,ymin+bbox_h)),int(xmin):int(min(1920,xmin+bbox_w)),:]\n","    cropped_img_shape = np.shape(cropped_img);\n","\n","    rows=cropped_img_shape[0]\n","    cols=cropped_img_shape[1]\n","\n","    if rows<cols:\n","        rows_to_pad_up=np.floor((cols-rows)/2)\n","        padding_up=np.zeros([int(rows_to_pad_up),cols,1])\n","\n","        rows_to_pad_down=cols-rows-rows_to_pad_up\n","        padding_down=np.zeros([int(rows_to_pad_down),cols,1])\n","\n","        cropped_img=np.vstack((padding_up,cropped_img,padding_down))\n","        ymin = ymin-rows_to_pad_up\n","\n","    elif cols<rows:\n","        cols_to_pad_left=np.floor((rows-cols)/2)\n","        padding_left=np.zeros([rows,int(cols_to_pad_left),1])\n","\n","        cols_to_pad_right=rows-cols-cols_to_pad_left\n","        padding_right=np.zeros([rows,int(cols_to_pad_right),1])\n","\n","        cropped_img=np.hstack((padding_left,cropped_img,padding_right))\n","        xmin = xmin-cols_to_pad_left\n","        \n","\n","    image_lrn=tf.image.resize(cropped_img,\n","                          [lrn_image_resolution,lrn_image_resolution],\n","                          method=tf.image.ResizeMethod.BILINEAR,\n","                          antialias=False\n","    )\n","    \n","    image_lrn = (image_lrn / 127.5) - 1.0\n","\n","\n","    image_lrn = tf.image.grayscale_to_rgb(image_lrn)\n","    image_lrn=np.expand_dims(image_lrn,0)\n","\n","    start=time.time()\n","    output_lrn=lrn_network(image_lrn)\n","    lrn_inference_time[i,:]=time.time()-start\n","\n","    keypoints=output_lrn[1].numpy()\n","\n","    #if output_lrn[0].numpy()<0:\n","    #  lrn_dataset_class = 0\n","    #else:\n","    #  lrn_dataset_class = 1\n","\n","    #export_predicted_class_lrn[i,:]=lrn_dataset_class\n","\n","    keypoints=np.reshape(keypoints,[num_keypoints*2,1])\n","    bbox_side = cropped_img.shape[0]\n","\n","    keypoints=(keypoints)*bbox_side\n","\n","    #Add xmin and ymin to x and y coordinates to recover values in original image frame\n","\n","    keypoints=keypoints.reshape(num_keypoints,2)\n","\n","    keypoints[:,0]+=xmin\n","    keypoints[:,1]+=ymin\n","\n","    export_keypoints[i,:]=keypoints.reshape(1,num_keypoints*2)\n","    \n","    start=time.time()\n","    success, R_vec, t_vec, inliers = cv2.solvePnPRansac(objectPoints,keypoints,cameraMatrix,distCoeffs,flags=cv2.SOLVEPNP_EPNP,reprojectionError=5)\n","    PnP_time[i,:]=time.time()-start\n","    \n","    Rotation_matrix, _ = cv2.Rodrigues(R_vec)\n","    scipy_rotation_matrix=Rot.from_matrix(Rotation_matrix)\n","    quat=scipy_rotation_matrix.as_quat()\n","\n","    if success==True:\n","        export_PnP_success[i,:]=success\n","        export_inliers_nr[i,:]=len(inliers)\n","\n","    export_position[i,:]=t_vec.transpose()\n","    export_quat[i,:]=quat\n","\n","    start=time.time()\n","    R_vec, t_vec=cv2.solvePnPRefineLM(objectPoints[inliers,:],keypoints[inliers,:],cameraMatrix,distCoeffs,R_vec, t_vec)\n","    LM_time[i,:]=time.time()-start\n","\n","    Rotation_matrix_LM, _ = cv2.Rodrigues(R_vec)\n","    scipy_rotation_matrix_LM=Rot.from_matrix(Rotation_matrix_LM)\n","    quat_LM=scipy_rotation_matrix_LM.as_quat()\n","    export_position_LM[i,:]=t_vec.transpose()\n","    export_quat_LM[i,:]=quat_LM\n","\n","    #image_overall_time[i,:]=time.time()-image_time_start\n","    #plt.imshow(image[:,:,0],cmap='gray', vmin=0, vmax=255)\n","    \n","    #plt.plot(keypoints[:,0],keypoints[:,1],'.')\n","    #plt.scatter=(keypoints[:,0],keypoints[:,1],10)\n","    #plt.show()\n","    \n","\n","\n","time_elapsed=time.time()-start_all\n","print(time_elapsed)"]},{"cell_type":"markdown","source":["Export inference data to json file format."],"metadata":{"id":"gH331xHFPmFn"},"id":"gH331xHFPmFn"},{"cell_type":"code","execution_count":null,"id":"f71e6907","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:24:01.056145Z","iopub.status.busy":"2022-05-28T11:24:01.055712Z","iopub.status.idle":"2022-05-28T11:24:02.091888Z","shell.execute_reply":"2022-05-28T11:24:02.090460Z"},"id":"f71e6907","papermill":{"duration":1.249949,"end_time":"2022-05-28T11:24:02.097617","exception":false,"start_time":"2022-05-28T11:24:00.847668","status":"completed"},"tags":[]},"outputs":[],"source":["import json\n","\n","i=-1;\n","for item in images_names:\n","  i=i+1;\n","  if i==0:\n","    data_all=[{\n","      'image': images_names[i],\n","      'bbox_coords': (export_bbox_coords[i]).tolist(),\n","      'sdn_inference_time': (sdn_inference_time[i]).tolist(),\n","      'keypoints': (export_keypoints[i]).tolist(),\n","      'lrn_inference_time': (lrn_inference_time[i]).tolist(),\n","      'PnP_success': (export_PnP_success[i]).tolist(),\n","      'PnP_inliers_nr': (export_inliers_nr[i]).tolist(),\n","      'PnP_time': (PnP_time[i]).tolist(),\n","      'LM_time': (LM_time[i]).tolist(),\n","      'Load_time': (load_image_time[i]).tolist(),\n","      'position': (export_position[i]).tolist(),\n","      'quaternions': (export_quat[i]).tolist(),\n","      'position_LM': (export_position_LM[i]).tolist(),\n","      'quaternions_LM': (export_quat_LM[i]).tolist(),\n","      'overall_image_time': (image_overall_time[i]).tolist(),\n","    }]\n","  else:\n","    data_item={\n","      'image': images_names[i],\n","      'bbox_coords': (export_bbox_coords[i]).tolist(),\n","      'sdn_inference_time': (sdn_inference_time[i]).tolist(),\n","      'keypoints': (export_keypoints[i]).tolist(),\n","      'lrn_inference_time': (lrn_inference_time[i]).tolist(),\n","      'PnP_success': (export_PnP_success[i]).tolist(),\n","      'PnP_inliers_nr': (export_inliers_nr[i]).tolist(),\n","      'PnP_time': (PnP_time[i]).tolist(),\n","      'LM_time': (LM_time[i]).tolist(),\n","      'Load_time': (load_image_time[i]).tolist(),\n","      'position': (export_position[i]).tolist(),\n","      'quaternions': (export_quat[i]).tolist(),\n","      'position_LM': (export_position_LM[i]).tolist(),\n","      'quaternions_LM': (export_quat_LM[i]).tolist(),\n","      'overall_image_time': (image_overall_time[i]).tolist(),\n","    }\n","    data_all.append(data_item)  \n","\n","parsed = json.dumps(data_all,indent=4)\n","\n","with open(os.path.join(json_dest_file),'w') as f:\n","        f.write(parsed)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":2106.803327,"end_time":"2022-05-28T11:24:05.432008","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-05-28T10:48:58.628681","version":"2.3.4"},"colab":{"name":"adversarial_inference.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}